{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Name: main.py\n",
    "# Purpose: Pull data from twitter, perform sentiment analysis and pull stock data\n",
    "#\n",
    "# Author(s):    David Little\n",
    "#\n",
    "# Created:      04/26/2021\n",
    "# Updated:\n",
    "# Update Comment(s):\n",
    "#\n",
    "# TO DO:\n",
    "#\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import regex as re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tweet):\n",
    "    data = {\n",
    "        'id': tweet['id'],\n",
    "        'created_at': tweet['created_at'],\n",
    "        'text': tweet['text'],\n",
    "        'retweet_count': tweet['public_metrics']['retweet_count'],\n",
    "        'like_count': tweet['public_metrics']['like_count'],\n",
    "        'reply_count': tweet['public_metrics']['reply_count']\n",
    "#        'quote_count': tweet['public_metrics']['quote_count']\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace = re.compile(r\"\\s+\")\n",
    "web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
    "tesla = re.compile(r\"(?i)@Tesla(?=\\b)\")\n",
    "user = re.compile(r\"(?i)@[a-z0-9_]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------- Twitter Pull  --------------------------------------------------------\n",
    "\n",
    "# setup the API request\n",
    "endpoint = 'https://api.twitter.com/2/tweets/search/recent'  # 'https://api.twitter.com/2/tweets/search/all'\n",
    "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
    "params = {\n",
    "    'query': '(tesla OR tsla OR elon musk and -spacex -is:retweet) (lang:en)', # \n",
    "    'max_results': '100',\n",
    "    'tweet.fields': 'created_at,lang,public_metrics'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtformat = '%Y-%m-%dT%H:%M:%SZ'  # the date format string required by twitter\n",
    "\n",
    "# we use this function to subtract 60 mins from our datetime string\n",
    "def time_travel(now, mins):\n",
    "    now = datetime.strptime(now, dtformat)\n",
    "    back_in_time = now - timedelta(minutes=mins)\n",
    "    return back_in_time.strftime(dtformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-10-29T07:49:44Z'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()  # get the current datetime, this is our starting point\n",
    "last_week = now - timedelta(days=6)  # datetime one week ago = the finish line\n",
    "now = now.strftime(dtformat)  # convert now datetime to format for API\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()  # initialize dataframe to store tweets\n",
    "while True:\n",
    "    if datetime.strptime(now, dtformat) < last_week:\n",
    "        # if we have reached 6 days ago, break the loop\n",
    "        break\n",
    "    pre60 = time_travel(now, 5)  # get x minutes before 'now'\n",
    "    # assign from and to datetime parameters for the API\n",
    "    params['start_time'] = pre60\n",
    "    params['end_time'] = now\n",
    "    response = requests.get(endpoint,\n",
    "                            params=params,\n",
    "                            headers=headers)  # send the request\n",
    "    time.sleep(2)\n",
    "    now = pre60  # move the window 60 minutes earlier\n",
    "    # iteratively append our tweet data to our dataframe\n",
    "    for tweet in response.json()['data']:\n",
    "        row = get_data(tweet)  # we defined this function earlier\n",
    "        if row['like_count']>=0 and row['retweet_count']>=0 and row['reply_count']>=0:   #row['like_count'] >=3:\n",
    "            df = df.append(row, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Sentiment Model ------------------------------------------------------\n",
    "\n",
    "#import flair #lstm model\n",
    "#sentiment_model = flair.models.TextClassifier.load('en-sentiment')\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "# we will append probability and sentiment preds later\n",
    "probs = []\n",
    "sentiments = []\n",
    "clean_tweets = []\n",
    "timestamp = []\n",
    "binary = []\n",
    "\n",
    "for time in df['created_at']:\n",
    "    timestamp.append(((datetime.strptime(time, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                      - timedelta(hours = 4)) #timezone\n",
    "                      + timedelta(hours = 0) #delay\n",
    "                     ).strftime('%Y-%m-%d')) # %H:00:00'))\n",
    "\n",
    "for tweet in df['text']:\n",
    "# we then use the sub method to replace anything matching\n",
    "    tweet = whitespace.sub(' ', tweet)\n",
    "    tweet = web_address.sub('', tweet)\n",
    "    tweet = tesla.sub('Tesla', tweet)\n",
    "    tweet = user.sub('', tweet)\n",
    "    if is_positive(tweet): binary.append(1)\n",
    "    else: binary.append(0)\n",
    "    #sentence = flair.data.Sentence(tweet)\n",
    "    #sentiment_model.predict(sentence)\n",
    "    # extract sentiment prediction\n",
    "    #sentiments.append(sentence.labels[0].value)  # 'POSITIVE' or 'NEGATIVE'\n",
    "    #if sentence.labels[0].value == 'NEGATIVE':\n",
    "    #    probs.append(-1 * sentence.labels[0].score)  # numerical score 0-1\n",
    "    #    binary.append(0)\n",
    "    #else:\n",
    "    #    probs.append(sentence.labels[0].score)  # numerical score 0-1\n",
    "     #   binary.append(1)\n",
    "    clean_tweets.append(tweet)\n",
    "    # print(tweet)\n",
    "    # print(' ')\n",
    "\n",
    "# add probability and sentiment predictions to tweets dataframe\n",
    "df['text_clean'] = clean_tweets\n",
    "#df['probability'] = probs\n",
    "#df['sentiment'] = sentiments\n",
    "df['binary'] = binary\n",
    "df['Date'] = timestamp\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"TwitterData_latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________________ Stock Data __________________________________________________________________\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "#tsla = yf.Ticker(\"TSLA\")\n",
    "tsla = yf.download( \"TSLA\",\n",
    "    start=datetime.strptime(df['created_at'].min(),'%Y-%m-%dT%H:%M:%S.%fZ').strftime('%Y-%m-%d'),\n",
    "    end=(datetime.strptime(df['created_at'].max(),'%Y-%m-%dT%H:%M:%S.%fZ')+timedelta(days = 2)).strftime('%Y-%m-%d'),\n",
    "    interval='1d' #'60m'\n",
    "        )#.reset_index()\n",
    "tsla_stock = tsla.pct_change().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = []\n",
    "for time in tsla_stock['Date']:\n",
    "    converted.append(time.strftime('%Y-%m-%d')) #  %H:00:00'))\n",
    "tsla_stock['Date'] = converted\n",
    "#tsla_stock['Date'] = pd.to_datetime(tsla_stock['Date'])\n",
    "tsla_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means = df.groupby(['Date'],  as_index=False).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_stock['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined = means.merge(tsla_stock, how='inner')\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined['like_count'].corr(combined['Close'])\n",
    "combined['binary'].corr(combined['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "\n",
    "# plot the data\n",
    "ax.plot(combined['binary'],combined['Close'], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tweepy\n",
    "\n",
    "#auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "#auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "#public_tweets = api.home_timeline()\n",
    "#for tweet in public_tweets:\n",
    "#    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
